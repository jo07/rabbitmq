{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='dimgrey'>Exchanges & multiple queues : FanOut Exchange </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='grey'> Till now ... </font>\n",
    "In the last tutorial 'Task Queues' We had producer producing multiple tasks to queues and the task being divided among the consumers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well this tutorial is all about\n",
    "> [Published log messages are going to be broadcast to all the receivers](https://www.rabbitmq.com/tutorials/tutorial-three-python.html#:~:text=published%20log%20messages%20are%20going%20to%20be%20broadcast%20to%20all%20the%20receivers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='dimgrey'>In the last tutorial we had a producer/publisher pushing messages to a default exchange and that exchange sending the message to declared queues and workers getting assigned the task parallely </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='dimgrey'> In this tutorial we are going to have a publisher sending messages to a specific exchange and that exchange pushing messages to all the queues in that exchange </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='dimgrey'> Exchange</font>\n",
    "><t> <font color='dimgrey'> Essentially its decoupling publisher and queues. It recieves messages from publishers and pushes to queues. </font>\n",
    "    \n",
    "><t> <font color='dimgrey'> There are multiple types of exchanges and in this tutorial we will learn about 'fanout' type. It has a publisher which sends messages to the exchange which broadcasts all the messages to all the queues in that exchange</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='dimgrey'> Last time we used the default exchange, here we will declare one first both while publishing and consuming </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel.exchange_declare(exchange='logs',\n",
    "                         exchange_type='fanout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  <font color='dimgrey'> This step is important since publishing to a non-existtent exchange is forbidden </font> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='dimgrey'> And when we publish a message we will mention the exchange </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel.basic_publish(exchange='logs',\n",
    "                      routing_key='',\n",
    "                      body=message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  <font color='dimgrey'> In fanout exchange type we don't need to specify the 'routing_key' since every queue subscribing to this exchange gets the messages/tasks</font> <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='dimgrey'> Consuming </font> <br>\n",
    "> <font color='dimgrey'> While consuming also you need to declare the exchange with same name, but you don't need to specify a queue name now and we can keep that info abstract </font> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color='dimgrey'> We can do just that by not specifing a name on the queue declaration </font> <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = channel.queue_declare(queue='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color='dimgrey'> Also we don't need to persist the messages in the queue once the consumer connection is closed. Use the exclusive flag to make this queue exclusively for that consumer </font> <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = channel.queue_declare(queue='', exclusive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color='dimgrey'> Also 'result.method.queue' will have the queue name value in it </font> <br>\n",
    "> <font color='dimgrey'> \"We will use that to bind the exchange to the queue\" </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='dimgrey'> Binding </font> <br>\n",
    "> <font color='dimgrey'> Earlier queues were subscribed to the default exchange now we need to specify the exchange the queue is gonna subscribe to</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel.queue_bind(exchange='logs',\n",
    "                   queue=result.method.queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color='dimgrey'> From now on all the tasks/messages in 'logs' exchange would get pushed to all the queues that binds to it </font> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='dimgrey'> Let's put it all together - Publisher </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter new taskm .\n",
      " [x] Sent 'm .'\n",
      "Enter new taskm ..\n",
      " [x] Sent 'm ..'\n",
      "Enter new taskm ...\n",
      " [x] Sent 'm ...'\n"
     ]
    }
   ],
   "source": [
    "# Emit_logs\n",
    "import pika\n",
    "import sys\n",
    "\n",
    "connection = pika.BlockingConnection(\n",
    "    pika.ConnectionParameters(host='localhost'))\n",
    "channel = connection.channel()\n",
    "\n",
    "channel.exchange_declare(exchange='logs', exchange_type='fanout')\n",
    "def sendQueue():\n",
    "    try:\n",
    "        while True:\n",
    "            # keep taking input till kernel is interrupted\n",
    "            message = input(\"Enter new task\")\n",
    "            channel.basic_publish(exchange='logs', routing_key='', body=message)\n",
    "            print(\" [x] Sent %r\" % message)\n",
    "    except KeyboardInterrupt:\n",
    "        # Exit gracefully\n",
    "        connection.close()\n",
    "sendQueue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='dimgrey'> If no queues are binded to the exchange yet, the messages gets discarded </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='dimgrey'> Let's put it all together - Consumer </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pika\n",
    "\n",
    "connection = pika.BlockingConnection(\n",
    "    pika.ConnectionParameters(host='localhost'))\n",
    "channel = connection.channel()\n",
    "\n",
    "channel.exchange_declare(exchange='logs', exchange_type='fanout')\n",
    "\n",
    "result = channel.queue_declare(queue='', exclusive=True)\n",
    "queue_name = result.method.queue\n",
    "\n",
    "channel.queue_bind(exchange='logs', queue=queue_name)\n",
    "\n",
    "print(' [*] Waiting for messages. To exit kernel -> Interrupt')\n",
    "\n",
    "def callback(ch, method, properties, body):\n",
    "    print(\" [x] %r\" % body)\n",
    "\n",
    "channel.basic_consume(\n",
    "    queue=queue_name, on_message_callback=callback, auto_ack=True)\n",
    "\n",
    "try:\n",
    "    channel.start_consuming()\n",
    "except KeyboardInterrupt:\n",
    "    # Exit gracefully\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='dimgrey'> Testing </font> \n",
    "<t><font color='dimgrey'> We will run publisher code from this notebook and we will create two worker nodes for consuming </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter new taskm .\n",
      " [x] Sent 'm .'\n",
      "Enter new taskm ..\n",
      " [x] Sent 'm ..'\n",
      "Enter new taskm ...\n",
      " [x] Sent 'm ...'\n",
      "Enter new taskm ...\n",
      " [x] Sent 'm ...'\n"
     ]
    }
   ],
   "source": [
    "#publisher\n",
    "# Emit_logs\n",
    "import pika\n",
    "import sys\n",
    "\n",
    "connection = pika.BlockingConnection(\n",
    "    pika.ConnectionParameters(host='localhost'))\n",
    "channel = connection.channel()\n",
    "\n",
    "channel.exchange_declare(exchange='logs', exchange_type='fanout')\n",
    "def sendQueue():\n",
    "    try:\n",
    "        while True:\n",
    "            # keep taking input till kernel is interrupted\n",
    "            message = input(\"Enter new task\")\n",
    "            channel.basic_publish(exchange='logs', routing_key='', body=message)\n",
    "            print(\" [x] Sent %r\" % message)\n",
    "    except KeyboardInterrupt:\n",
    "        # Exit gracefully\n",
    "        connection.close()\n",
    "sendQueue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Both the worker node recieved both the messages. In the next tutorial we try to subscribe to a subset of messages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
